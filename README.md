# README

## Contexte
Ce projet explore l’optimisation de modèles de machine learning à l’aide de différents algorithmes d’optimisation (SGD, RMSProp, Adagrad, Adam) et de schedulers (LRScheduler, LRSchedulerOnPlateau). Nous avons implémenté des tests approfondis pour comparer les performances de ces techniques sur des jeux de données synthétiques (linéaires et non linéaires) ainsi que sur un réseau de neurones simple.

Les tests incluent :
- La comparaison des optimiseurs sur 100 époques avec ou sans scheduler.
- L’évaluation de la convergence des pertes avec des visualisations linéaires et logarithmiques.

## Auteurs
- **Samy Hadj-Said**
- **Jason Perez**